{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "94b668c5",
      "metadata": {
        "id": "94b668c5"
      },
      "source": [
        "# **White Blood Cell Classification**\n",
        "\n",
        "## Objective\n",
        "In this notebook, you will train a convolutional neural network (ConvNet) to classify white blood cells into two categories:\n",
        "1. Lymphoblasts (indicative of leukemia)\n",
        "2. Normal white blood cells\n",
        "\n",
        "We will use a custom dataset for this classification task. Details on the initial dataset can be found here: https://scotti.di.unimi.it/all/\n",
        "\n",
        "The exercise will guide you step-by-step from data loading and preparation to building and training a deep learning model.\n",
        "\n",
        "Types of leukemia: https://www.leukaemiacare.org.uk/types-of-leukaemia/\n",
        "\n",
        "Morphology of leukemia: https://www.sciencedirect.com/science/article/pii/S0185106315000724\n",
        "\n",
        "Examples of different WBC (Fig. 2): https://www.nature.com/articles/s41597-023-02378-7\n",
        "\n",
        "Review on blood film analysis analysis with AI: https://www.sciencedirect.com/science/article/pii/S0268960X23001054\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DAqBLFGZ6W1R",
      "metadata": {
        "id": "DAqBLFGZ6W1R"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bc47a56",
      "metadata": {
        "id": "3bc47a56"
      },
      "source": [
        "## ðŸ“š 0. Import Libraries (Nothing to do)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc54338d",
      "metadata": {
        "id": "cc54338d"
      },
      "outputs": [],
      "source": [
        "# Importing necessary libraries\n",
        "import tensorflow as tf  # TensorFlow for deep learning\n",
        "import os  # For handling file paths\n",
        "import numpy as np  # For data manipulation\n",
        "import matplotlib.pyplot as plt  # For visualizing the dataset\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator  # For loading and augmenting image data\n",
        "from sklearn.model_selection import train_test_split  # For splitting custom dataset into train and test\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "418618d9",
      "metadata": {
        "id": "418618d9"
      },
      "source": [
        "## ðŸ‘“ 1. Download the data (Nothing to do)\n",
        "You will use a custom dataset of images that contain lymphoblasts and normal white blood cells. Make sure the dataset is organized in two folders: \"lymphoblast\" and \"normal\", with images placed in their respective folders.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5437b1d",
      "metadata": {
        "id": "a5437b1d"
      },
      "outputs": [],
      "source": [
        "# Define dataset paths\n",
        "base_dir = '/content/drive/MyDrive/all_data/'  # Update this to the actual path\n",
        "#normal_dir = os.path.join(base_dir, 'normal')\n",
        "#lymphoblast_dir = os.path.join(base_dir, 'lymphoblasts')\n",
        "\n",
        "# Define parameters\n",
        "IMG_HEIGHT, IMG_WIDTH = 128, 128\n",
        "BATCH_SIZE = 32\n",
        "NUM_EPOCHS=10\n",
        "RAN_SEED=17\n",
        "\n",
        "# Use ImageDataGenerator for loading and splitting data\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255,  # Normalize pixel values\n",
        "    validation_split=0.5)  # Split 20% of the data for validation\n",
        "\n",
        "# Creating train and validation datasets\n",
        "train_data = datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    subset='training',\n",
        "    seed=RAN_SEED\n",
        ")\n",
        "\n",
        "validation_data = datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    subset='validation',\n",
        "    seed=RAN_SEED\n",
        ")\n",
        "\n",
        "print(\"Training and validation datasets prepared successfully.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11e71707",
      "metadata": {
        "id": "11e71707"
      },
      "source": [
        "###  1.2 : Visualize the Dataset\n",
        "\n",
        "â— Display 10 images from the training dataset to understand the data better. Use the function bellow or build your own.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b676ad7",
      "metadata": {
        "id": "4b676ad7"
      },
      "outputs": [],
      "source": [
        "# Function to display a few images from the dataset\n",
        "def visualize_dataset(dataset, num_images=5):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    for i, (image, label) in enumerate(dataset):\n",
        "        if i >= num_images:\n",
        "            break\n",
        "        plt.subplot(1, num_images, i + 1)\n",
        "        plt.imshow(image[0])  # Image comes as a batch, so we take the first image\n",
        "        plt.title(\"Lymphoblast\" if label[0] == 1 else \"Normal\")\n",
        "        plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# Displaying a few images from the training dataset\n",
        "## ... add code here ... ##\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06c927d3",
      "metadata": {
        "id": "06c927d3"
      },
      "source": [
        "## ðŸ§± 3. Build a simple ConvNet\n",
        "\n",
        "Here you will build a simple convolutional neural network (CNN) to classify lymphoblasts and normal white blood cells.\n",
        "\n",
        "â— **Add in the missing layers**. To prevent overfitting, add also 0.2 dropout rate during training where specified. Hint: check out https://keras.io/api/layers/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa0f1a70",
      "metadata": {
        "id": "fa0f1a70"
      },
      "outputs": [],
      "source": [
        "# Build a simple CNN model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
        "    #Add a pooling layer here. You need to add \",\" after each layer\n",
        "    ## add your code here ###,\n",
        "\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    #Add a pooling layer here. You need to add \",\" after each layer\n",
        "    ## add your code here #### ,\n",
        "\n",
        "    #Add a Convolutional layer here with 64 filters. You need to add \",\" after each layer\n",
        "    ## add your code here.... ##,\n",
        "\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "     #Add a dropout layer here with a rate of 0.2. [In sequential mode, you need to add \",\" after each layer]\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')  # Binary classification output\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "â—**How many parameters does your model have?** Hint: use the keras.model API to summarize your model: https://keras.io/api/models/"
      ],
      "metadata": {
        "id": "ghNlS-1y8gYO"
      },
      "id": "ghNlS-1y8gYO"
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the model summary\n",
        "## .. add line of code here .. ##"
      ],
      "metadata": {
        "id": "zK0GO88Q8kAH"
      },
      "id": "zK0GO88Q8kAH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "018a756d",
      "metadata": {
        "id": "018a756d"
      },
      "source": [
        "### 3.1 Train the Model\n",
        "\n",
        "We will now train the model using the training and validation datasets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "852c14e0",
      "metadata": {
        "id": "852c14e0"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_data,\n",
        "    validation_data=validation_data,\n",
        "    epochs=NUM_EPOCHS,  # You can increase the number of epochs based on your needs\n",
        "    verbose=1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1573b1fc",
      "metadata": {
        "id": "1573b1fc"
      },
      "source": [
        "### 3.1: Evaluate and Visualize Results\n",
        "\n",
        "â—Evaluate your model on the validation data. Hint: call the apropriate method using the keras API : https://keras.io/api/models/\n",
        "\n",
        "What is the validation accuracy?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41e89cab",
      "metadata": {
        "id": "41e89cab"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = ### write your line of code here ###\n",
        "print(f\"Validation Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Plot training and validation accuracy over epochs\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(len(acc))\n",
        "\n",
        "plt.figure(figsize=(14, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "FpBORcAkrTaE",
      "metadata": {
        "id": "FpBORcAkrTaE"
      },
      "source": [
        "## âž¡ï¸ 4. Transfer Learning\n",
        "\n",
        "In this section, you will use a pretrained MobileNet model, leveraging its features for classifying lymphoblasts vs normal white blood cells.\n",
        "\n",
        "â—Modify the code below so that your model uses MobileNet's convolutional layers (without the top fully connected layers) pretrained on the ImageNet dataset. Hint: checkout the keras aplications examples: https://keras.io/api/applications/\n",
        "\n",
        "â—Add a global pooling layer after the base model (Hint: it's already imported).\n",
        "\n",
        "â— Compare the following the following:\n",
        "\n",
        "a) train only the FC layers (freezing the convnet layers)\n",
        "\n",
        "b) train from scratch (no pre-trained weights) - (only if you have time left)\n",
        "\n",
        "c) fine-tune all layers - (only if you have time left)\n",
        "\n",
        "â—For a) you need to freeze the MobileNet base model layers so that only the newly added fully connected dense layers are optimized. (Hint: check out the keras layer documentation: https://keras.io/api/layers/base_layer/#layer-class. You need to change the value of one of the layer attributes) Or have a look at : https://keras.io/guides/transfer_learning/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Hlj7hC6SrUwW",
      "metadata": {
        "id": "Hlj7hC6SrUwW"
      },
      "outputs": [],
      "source": [
        "import tensorflow\n",
        "from tensorflow.keras.applications.mobilenet import MobileNet\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import Input\n",
        "# Load MobileNetV2 pretrained on ImageNet and add custom layers for our binary classification task\n",
        "input_tensor = Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
        "# create the base pre-trained model on ImageNet with a custom input tensor\n",
        "\n",
        "base_model = MobileNet(\n",
        "     ### ... add lines here ...###\n",
        ")\n",
        "\n",
        "# Freeze the base model to use it as a feature extractor\n",
        "## ... add code here ... ##\n",
        "\n",
        "# Add custom layers on top of the base model\n",
        "model_mobilenet = tf.keras.Sequential([\n",
        "    base_model,\n",
        "    ## ... add code here ##\n",
        "    # Add a global spatial average pooling layer\n",
        "    ## .. add code here ###,\n",
        "\n",
        "    # let's add a fully-connected layer\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.3),  # Add dropout to prevent overfitting\n",
        "    # and a classification layer\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')  # Binary classification output\n",
        "])\n",
        "\n",
        "#model_mobilenet2 = tensorflow.keras.models.clone_model(model_mobilenet)\n",
        "\n",
        "# Compile the model\n",
        "model_mobilenet.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Print the model summary\n",
        "#model_mobilenet.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7_OtkBDlrbSJ",
      "metadata": {
        "id": "7_OtkBDlrbSJ"
      },
      "source": [
        "### 4.1 Train the MobileNet Model (Nothing to do)\n",
        "\n",
        "You will now train the model using the training and validation datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PlopdD4orekB",
      "metadata": {
        "id": "PlopdD4orekB"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "history_mobilenet = model_mobilenet.fit(\n",
        "    train_data,\n",
        "    validation_data=validation_data,\n",
        "    epochs=NUM_EPOCHS,  # You can increase the number of epochs based on your needs\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Uc58vYq1ut_r",
      "metadata": {
        "id": "Uc58vYq1ut_r"
      },
      "source": [
        "### 4.2 Visualize the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Hg7zkbFYusLs",
      "metadata": {
        "id": "Hg7zkbFYusLs"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model_mobilenet.evaluate(validation_data)\n",
        "print(f\"Validation Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Plot training and validation accuracy over epochs\n",
        "acc = history_mobilenet.history['accuracy']\n",
        "val_acc = history_mobilenet.history['val_accuracy']\n",
        "loss = history_mobilenet.history['loss']\n",
        "val_loss = history_mobilenet.history['val_loss']\n",
        "\n",
        "epochs_range = range(len(acc))\n",
        "\n",
        "plt.figure(figsize=(14, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2VhzF3vJwKGT",
      "metadata": {
        "id": "2VhzF3vJwKGT"
      },
      "source": [
        "## ðŸ”§ 5. Data Augmentation\n",
        "\n",
        "To make our model more robust and reduce overfitting, here you will apply data augmentation techniques.\n",
        "\n",
        "\n",
        "â— **Add augmentation layers to your model before the first convolutional layer below.** An example of such a layer is provided. Add one geometrical augmentation and one spectral (related to the image color/luminance). *Hint*: use the image augmentation layers provided by the keras api:\n",
        "https://keras.io/api/layers/preprocessing_layers/image_augmentation/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XF7wcaj4wK-O",
      "metadata": {
        "id": "XF7wcaj4wK-O"
      },
      "outputs": [],
      "source": [
        "# Adding data augmentation to the training dataset\n",
        "\n",
        "# Add augmentation layers before the base model\n",
        "model_mobilenet2 = tf.keras.Sequential([\n",
        "    #Add augmentation layers here [In sequential mode, you need to add \",\" after each layer]\n",
        "   ##...add line of code here ..##\n",
        "\n",
        "    base_model,\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.3),  # Add dropout to prevent overfitting\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')  # Binary classification output\n",
        "])\n",
        "# Compile the model\n",
        "model_mobilenet2.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "# Re-train the original model with augmented data\n",
        "history_augmented = model_mobilenet2.fit(\n",
        "    train_data,\n",
        "    validation_data=validation_data,\n",
        "    epochs=NUM_EPOCHS,  # You can adjust the number of epochs\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XfPA_8c4wQwP",
      "metadata": {
        "id": "XfPA_8c4wQwP"
      },
      "source": [
        "### 5.1 Visualize the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fEUYKjCqwRvF",
      "metadata": {
        "id": "fEUYKjCqwRvF"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model_mobilenet2.evaluate(validation_data)\n",
        "print(f\"Validation Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Plot training and validation accuracy over epochs\n",
        "acc = history_augmented.history['accuracy']\n",
        "val_acc = history_augmented.history['val_accuracy']\n",
        "loss = history_augmented.history['loss']\n",
        "val_loss = history_augmented.history['val_loss']\n",
        "\n",
        "epochs_range = range(len(acc))\n",
        "\n",
        "plt.figure(figsize=(14, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.2 Compare the performance of your models\n",
        "\n",
        "â—**Plot the ROC curves and compute the AUC for each of your trained models**. Use the function bellow or build your own.  "
      ],
      "metadata": {
        "id": "sFPpF0Mb_nGl"
      },
      "id": "sFPpF0Mb_nGl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EGIN8b2gBHpH",
      "metadata": {
        "id": "EGIN8b2gBHpH"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "import numpy as np\n",
        "\n",
        "# Function to plot ROC curves for multiple models on the same plot\n",
        "def plot_roc_curves(models, validation_data_list, labels, title=\"ROC Curve Comparison\"):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    # Iterate over each model and its corresponding validation data\n",
        "    for model, validation_data, label in zip(models, validation_data_list, labels):\n",
        "        y_true = []\n",
        "        y_pred = []\n",
        "\n",
        "        # Get true labels and predicted probabilities\n",
        "        for images, labels_batch in validation_data:\n",
        "            y_true.extend(labels_batch)\n",
        "            preds = model.predict(images)\n",
        "            y_pred.extend(preds)\n",
        "\n",
        "            # Break after one full pass (since it's a generator)\n",
        "            if len(y_true) >= validation_data.samples:\n",
        "                break\n",
        "\n",
        "        y_true = np.array(y_true)\n",
        "        y_pred = np.array(y_pred)\n",
        "\n",
        "        # Compute False Positive Rate (FPR) and True Positive Rate (TPR)\n",
        "        fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "\n",
        "        # Plot the ROC Curve for the current model\n",
        "        plt.plot(fpr, tpr, lw=2, label=f'{label} (AUC = {roc_auc:.2f})')\n",
        "\n",
        "    # Plot the random guess line\n",
        "    plt.plot([0, 1], [0, 1], color='gray', linestyle='--')  # Random guess line\n",
        "\n",
        "    # Configure plot settings\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(title)\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "# Plot ROC curves for the original model and MobileNet models on the same plot\n",
        "\n",
        "###... Add your code here ... ###\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}